{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3414c1-df22-411f-a924-eb41bb712cac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from statistics import mode\n",
    "import numpy as np\n",
    "path = 'data/'\n",
    "from tqdm import tqdm\n",
    "import hashlib\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9571112d-eda4-4c03-ba07-b9b56bb6744f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Rename files\n",
    "The obtained data files from the SDSS API were saved as 'result (x).csv' by default. This code was used to automatically rename them to the respecting year and month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7523e057-555a-45d9-8ac4-db5bfd0035dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f for f in os.listdir(path) if f.endswith('.csv') and f.startswith(\"result\")]\n",
    "\n",
    "for file_name in files:\n",
    "    print(f'-> Checking {file_name}')\n",
    "    file_path = os.path.join(path, file_name)\n",
    "\n",
    "    file = pd.read_csv(file_path, encoding=\"latin-1\", nrows=20)\n",
    "    year = (file.iloc[19, 3])\n",
    "    month = (file.iloc[19, 4])\n",
    "\n",
    "    if not year or not month or pd.isnull(year) or pd.isnull(month) or pd.isna(year) or pd.isna(\n",
    "            month) or year == \"nan\" or month == \"nan\":\n",
    "        print(f\"Skipped {file_name}\")\n",
    "        print(file)\n",
    "        continue\n",
    "\n",
    "    new_file_name = f'{int(year)}-{int(month)}.csv'\n",
    "    new_file_path = os.path.join(path, new_file_name)\n",
    "\n",
    "    try:\n",
    "        os.rename(file_path, new_file_path)\n",
    "        print(f'Renamed {file_name} to {new_file_name}')\n",
    "    except IndexError:\n",
    "        print(f'Error: Unable to extract year and month from {file_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2815582c-e342-435d-9617-cff52614a13e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Format Files\n",
    "Multiple preprocessing steps have been undertaken, as seen here. Line breaks, redundant whitespaces, missing or wrong values have been deleted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707ead45-9c50-4378-a063-c2f448c98598",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files = [f for f in os.listdir(path) if f.endswith('.csv')]\n",
    "\n",
    "for file_name in files:\n",
    "    print(f\"Starting with {file_name}\")\n",
    "    file_path = os.path.join(path, file_name)\n",
    "    sdss = pd.read_csv(file_path, on_bad_lines=\"skip\", encoding=\"latin-1\",\n",
    "                       lineterminator=\"\\n\",\n",
    "                       dtype={\"statement\": str, \"runtime\": float, \"resultsize\": 'Int64', \"yy\": 'Int64',\n",
    "                              \"mm:\": 'Int64', \"dd\": 'Int64'})\n",
    "\n",
    "    sdss[\"statement\"] = sdss[\"statement\"].replace(\"\\n\", \"\", regex=True).replace(r'\\s+', ' ', regex=True).str.lower().str.strip()\n",
    "\n",
    "    sdss.dropna(inplace=True)\n",
    "    \n",
    "    sdss = sdss[~pd.to_numeric(sdss['statement'], errors='coerce', downcast=\"float\").notnull()]\n",
    "    sdss = sdss[sdss['runtime'] > 0.0]\n",
    "    sdss[\"resultsize\"] = sdss[\"resultsize\"].astype(int)\n",
    "    sdss[\"dd\"] = sdss[\"dd\"].astype(int)\n",
    "    sdss[\"mm\"] = sdss[\"mm\"].astype(int)\n",
    "    sdss[\"yy\"] = sdss[\"yy\"].astype(int)\n",
    "\n",
    "    minYear = int(sdss[\"yy\"].min())\n",
    "    minMonth = int(sdss[\"mm\"].min())\n",
    "    minDay = int(sdss[\"dd\"].min())\n",
    "    maxYear = int(sdss[\"yy\"].max())\n",
    "    maxMonth = int(sdss[\"mm\"].max())\n",
    "    maxDay = int(sdss[\"dd\"].max())\n",
    "    count = (sdss[\"statement\"].count())\n",
    "    print(f\"{file_name} ranging from {minYear}-{minMonth}-{minDay} to {maxYear}-{maxMonth}-{maxDay} with {count} lines\")\n",
    "\n",
    "    sdss.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ad19a0-68fe-41ee-84f6-d545b0e3e3d8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Delete Similar\n",
    "All files combined resulted in over 150 million queries. Upon manual investigation, it could be seen that many queries are very similar to each other. Therefore, the following code was applied to reduce the similarities to mitigate overfitting of models. For that, from all queries that were the same without numbers or had the first 50 % or 100 characters in common, one was randomly sampled. Hasing was used to speed up the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44c8c98-7989-435f-a783-26d34d8cffc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hash(statement):\n",
    "    hash_object = hashlib.sha256(statement.encode())\n",
    "    return hash_object.hexdigest()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024151eb-619f-4d48-b133-c8f4992758d7",
   "metadata": {},
   "source": [
    "Sample one of all queries that are the same without digits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813c4f6e-22eb-4182-a0f4-7491abd59a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f for f in os.listdir(path) if f.endswith(\".csv\")]\n",
    "final_df = pd.read_csv(f\"{path}empty.csv\")\n",
    "for file_name in tqdm(files):\n",
    "    file_path = os.path.join(path, file_name)\n",
    "    df = pd.read_csv(file_path, on_bad_lines=\"skip\", encoding=\"latin-1\",\n",
    "                       lineterminator=\"\\n\",\n",
    "                       dtype={\"statement\": str, \"runtime\": float, \"resultsize\": 'Int64', \"yy\": 'Int64',\n",
    "                              \"mm:\": 'Int64', \"dd\": 'Int64'})\n",
    "    final_df = pd.concat([final_df, df], ignore_index=True, sort=False)\n",
    "\n",
    "    similar_statements = {}\n",
    "    for i,statement in enumerate(final_df[\"statement\"]):\n",
    "        no_digits = re.sub(r'[0-9]', '', statement)\n",
    "        statement_hash = compute_hash(no_digits)\n",
    "        if statement_hash not in similar_statements:\n",
    "            similar_statements[statement_hash] = [i]\n",
    "        else:\n",
    "            similar_statements[statement_hash].append(i)\n",
    "    unique_statements = [random.choice(statements) for statements in similar_statements.values()]\n",
    "    final_df = final_df[final_df.index.isin(unique_statements)]\n",
    "\n",
    "print(len(final_df))\n",
    "final_df.to_csv(f\"{path}full.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8e002b-0355-4f6a-a9be-279d056dfa89",
   "metadata": {},
   "source": [
    "Sample one of all queries that are the same in the first half:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13679f85-9f8d-49b3-9dfb-39cd078a9990",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.read_csv(f\"{path}full.csv\", on_bad_lines=\"skip\", encoding=\"latin-1\",\n",
    "                       lineterminator=\"\\n\",\n",
    "                       dtype={\"statement\": str, \"runtime\": float, \"resultsize\": 'Int64', \"yy\": 'Int64',\n",
    "                              \"mm:\": 'Int64', \"dd\": 'Int64'})\n",
    "print(f\"initial df: {len(final_df)}\")\n",
    "final_df.reset_index()\n",
    "similar_statements = {}\n",
    "for i,statement in enumerate(final_df[\"statement\"]):\n",
    "    statement_len=int(len(statement)*0.5)\n",
    "    statement_hash = compute_hash(statement[:statement_len])\n",
    "    if statement_hash not in similar_statements:\n",
    "        similar_statements[statement_hash] = [i]\n",
    "    else:\n",
    "        similar_statements[statement_hash].append(i)\n",
    "\n",
    "# Randomly sample one statement from each group\n",
    "unique_statements = [random.choice(statements) for statements in similar_statements.values()]\n",
    "final_df = final_df[final_df.index.isin(unique_statements)]\n",
    "\n",
    "print(f\"final df: {len(final_df)}\")\n",
    "final_df.to_csv(f\"{path}full.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08752a9-4d0d-4a58-a809-64716b191c3b",
   "metadata": {},
   "source": [
    "Sample one of all queries that have the first 100 characters in common:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793d6c0b-f277-4a8a-b5a3-200b34a658f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.read_csv(f\"{path}full.csv\", on_bad_lines=\"skip\", encoding=\"latin-1\",\n",
    "                       lineterminator=\"\\n\",\n",
    "                       dtype={\"statement\": str, \"runtime\": float, \"resultsize\": 'Int64', \"yy\": 'Int64',\n",
    "                              \"mm:\": 'Int64', \"dd\": 'Int64'})\n",
    "print(f\"initial df: {len(final_df)}\")\n",
    "final_df.reset_index()\n",
    "similar_statements = {}\n",
    "for i,statement in enumerate(final_df[\"statement\"]):\n",
    "    statement_hash = compute_hash(statement[:100])\n",
    "    if statement_hash not in similar_statements:\n",
    "        similar_statements[statement_hash] = [i]\n",
    "    else:\n",
    "        similar_statements[statement_hash].append(i)\n",
    "\n",
    "# Randomly sample one statement from each group\n",
    "unique_statements = [random.choice(statements) for statements in similar_statements.values()]\n",
    "final_df = final_df[final_df.index.isin(unique_statements)]\n",
    "\n",
    "print(f\"final df: {len(final_df)}\")\n",
    "final_df.to_csv(f\"{path}full.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f3bfc0-726d-4dd2-acb4-40062ef3abee",
   "metadata": {},
   "source": [
    "Train and test data split:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f24e28-a539-4a3d-babe-569c3c56d182",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.sample(frac=1)\n",
    "\n",
    "train_size = int(0.9 * len(final_df))\n",
    "train_df = final_df.iloc[:train_size]\n",
    "test_df = final_df.iloc[train_size:]\n",
    "\n",
    "train_df[\"statement\"] = train_df[\"statement\"].str.slice(0,512)\n",
    "test_df[\"statement\"] = test_df[\"statement\"].str.slice(0,512)\n",
    "\n",
    "train_df.to_csv(f\"{path}train.csv\", index=False)\n",
    "test_df.to_csv(f\"{path}test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346069ea-f978-43a8-b033-3d01522a0458",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_df))\n",
    "print(len(test_df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
